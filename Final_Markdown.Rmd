---
title: "Final Project"
author: "Guangze Sun & Nick Lenz"
date: "2024-12-10"
output:
  html_document:
    code_folding: hide
---
## 0. Pechakucha presentation

https://www.youtube.com/watch?v=AV7JtyboBkQ

## 1. Use case motivation

For years, Belgium transportation planners have struggled to accurately predict overcrowding on their trains. The national railway company, SNCB (NMBS), coordinates with other passenger railroad companies to release schedules up to four months in advance. Due to the advanced nature of these schedules, SNCB has difficulty preventing overcrowding and can only limit overcrowding in real-time by releasing additional trains (or “special trains”). These special trains relieve pressure on the system and prevent dangerous levels of overcrowding. However, as the COVID-19 pandemic has changed the way people work and weakened the traditional 9-5 work schedule, demand for trains has fundamentally changed. Whereas before the pandemic, train transportation planners could generally extrapolate past patterns onto future schedules, planning to limit overcrowding after the pandemic does not have these same patterns. There may be new work travel patterns related to work from home and more leisure travel on off days. SNCB has already struggled to respond to new travel demands. In 2021, overcrowding on summer trains to the Belgian seaside resulted in some trains reaching 130% of their capacity, a dangerous level of overcrowding (Chini, 2021). Yet, transportation planners still need to make the same predictions months in advance and release those schedules to the public. This new era requires a new way to predict overcrowding on trains and allow transportation planners to make schedule adjustments months in the past that will have positive impacts on schedules in the future. 


Therefore, we developed a model that will accurately predict for train overcrowding based on past data. Our model is based on a series of datasets related to past trains including the frequency, station, line, weather, time, day of the week, etc. The model uses a simple binary “yes/no” method relating to train overcrowding, with a logistic regression used to predict overcrowding on the various inputs. We also spent time engineering features to create a model that reveals patterns in the data and used those patterns to create a better model. Our model is designed to be better than the business-as-usual case of predicting overcrowding directly from overcrowding observed in past train schedules. Instead, our model takes into account new inputs (like the weather, the frequency of the train, and the line)  to create predictions that transportation planners can rely on. It also incorporates a cost-benefit analysis of train overcrowding to allow SNCB planners to optimize schedule planning. In use, our model would be used as part of an app, ScheduRail, where transportation planners input their proposed schedule and our model creates predictions for overcrowding based on that schedule. The transportation planner can then go back, add trains to the schedule (or keep it the same), and re-input the schedule to our model until the risk of overcrowding is properly minimized. 


Our solution to the problem of scheduling for Belgian transportation planners represents a firm data-based approach that has real results. Moreover, what our model allows for is great flexibility. We plan for the model to constantly adapt its data within the time of the scheduled prediction. Therefore, the model will constantly be fine-tuned to create predictions that are most likely to be accurate for the future schedule. That flexibility and constant adaption, while featuring a large number of input factors, makes our model the ideal one to use to predict future overcrowding in schedules. 


We believe that this approach is the best way to create accurate predictions and that the business-as-usual approach risks falling further behind as transportation patterns change. The method for predicting transportation in Belgian rail needs a new, 21st-century data-based solution to prevent overcrowding on trains and give riders of SNCB and other affiliated companies the best experience possible.

## 2. Data wrangling

We used a variety of datasets to create accurate predictions. The base dataset (the one guiding our predictions, and the impetus for our model creation) is a dataset containing train times, the date, the type of train (suburban, inter-city, international, etc.), and the occupancy characteristics of the train (low, medium, high). The base dataset is a highly incomplete picture of trains in Belgium from the end of July 2016 to the end of October 2016 (Note: the data in this analysis is designed to be changed as new inputs emerge).  An affiliated dataset also had a list of stations that aligned with the numeric variables presented in the first dataset. To understand spatial relationships, we utilized datasets containing the geographic coordinates of train stations across Belgium. We then crossed the coordinates of this dataset with the existing stations presented in the first dataset to property select stations existing in both datasets. We also inputted a Shapefile of Belgium  to understand occupancy characteristics by line in a spatial manner. This method allowed us to discover patterns that led to further analyses (described later) on the impact of origin/destination pairs on occupancy characteristics. We believed that another important aspect of train occupancy characteristics was the weather. For instance, during the colder months, people may choose to take the train more than in the warmer months. Due to Belgium's large mode share for cycling, with up to 30% of workers commuting by bicycle, seasonal weather patterns could have drastic impacts on overcrowding potential, especially for suburban or local trains. Therefore, we analyzed temperature data per day from the Royal Meteorological Institute of Belgium as a considered input into our model (while cross-referencing the days with the original base dataset). We also collected data for average station boardings for weekends and weekdays. This dataset informed us of the overcrowding potential originating for certain stations and was helpful when contextualizing origin/destination pairs discovered in the base dataset. Finally, we imported a dataset on the arrivals and departures of trains per station per day. This dataset was important to augment the base dataset, which had a very small sample set of Belgian trains. This dataset allowed us to understand the frequency associated with the trains in the original dataset (since it did not include all of the trains from Belgium). Moreover, having a base for the frequency per hour of trains in a station is helpful for scheduling changes, as transportation planners can optimize frequency while accounting for overcrowding. Since our app, ScheduRail, is designed to be utilized to optimize schedules,  we considered frequency an essential variable to support proper optimization. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
Sys.setlocale("LC_TIME", "C")
```

```{r package}
library(tidyverse)
library(sf)
library(gridExtra)
library(grid)
library(caret)
library(spdep)
library(plotROC)
library(pROC)
library(broom)
library(knitr)
```

```{r read data}
data <- read.csv('trains_train.csv') %>%
  filter(!(to %in% c("000000000", "(null)"))) %>%
  filter(!(from %in% c("(null)"))) %>%
  mutate(
    OD = paste(from, to, sep = "/"),
    type = ifelse(
      str_detect(vehicle, "[A-Za-z]"),
      str_extract(vehicle, "^[A-Za-z]+"),
      "Extra"
    ),
    occupancy_classifier = case_when(occupancy == "high" ~ 1, TRUE ~ 0)
  ) %>%
  dplyr::select(-connection, -occupancy, -vehicle)
```

```{r temporal}
data <- data %>%
  mutate(
    time_24hr = format(parse_date_time(trimws(time), orders = "HMS p"), "%H:%M:%S"),
    datetime_combined = ymd(date) + hms(time_24hr),
    interval60 = floor_date(datetime_combined, "hour"),
    #interval30 = floor_date(datetime_combined, "30 minutes"),
    hour = hour(interval60),
    #minute = minute(interval30),
    #halfhour = hour + ifelse(minute >= 30, 0.5, 0),
    dotw = wday(interval60, label = TRUE),
    # is_weekend = ifelse(dotw %in% c("Sat", "Sun"), "Weekend", "Weekday"),
    date = ymd(date)
  )
```

```{r spatial}
stations <- read.csv('stations.csv') %>%
  mutate(
    code = str_extract(URI, "[^/]{9}$"),
    Weekday = as.numeric(Weekday),
    Weekend = rowMeans(cbind(
      as.numeric(Saturday), as.numeric(Sunday)
    ), na.rm = TRUE)
  ) %>%
  filter(country.code == "be") %>%
  select(code, name, longitude, latitude, Weekday, Weekend) %>%
  filter(code %in% unique(c(data$from, data$to)))

from_avg <- data %>%
  group_by(from) %>%
  summarize(from_count = n(),
            from_avg = mean(occupancy_classifier, na.rm = TRUE))

to_avg <- data %>%
  group_by(to) %>%
  summarize(to_count = n(),
            to_avg = mean(occupancy_classifier, na.rm = TRUE))

stations <- stations %>%
  mutate(Overall = Weekday * 5 / 7 + Weekend * 2 / 7) %>%
  left_join(from_avg, by = c("code" = "from")) %>%
  left_join(to_avg, by = c("code" = "to")) %>%
  replace(is.na(.), 0) %>%
  mutate(
    overall_count = from_count + to_count,
    overall_avg = (from_avg * from_count + to_avg * to_count) / (from_count + to_count)
  )

stations_sf <- stations %>%
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326)

# stations <- stations %>%
#   mutate(level = case_when(
#     Overall > 10000 ~ "A",
#     Overall > 1000 & Overall <= 10000 ~ "B",
#     Overall <= 1000 ~ "C"
#   ))

data <- data %>%
  filter(from %in% stations$code & to %in% stations$code)
# %>% left_join(stations %>% select(code, level) %>% rename(from_level = level),
#             by = c("from" = "code")) %>%
#     left_join(stations %>% select(code, level) %>% rename(to_level = level),
#             by = c("to" = "code")) %>%
#     mutate(OD_level = paste(from_level, to_level, sep = "/"))

data <- data %>%
  left_join(
    stations %>% select(code, Overall) %>% rename(from_passenger = Overall),
    by = c("from" = "code")
  ) %>%
  left_join(
    stations %>% select(code, Overall) %>% rename(to_passenger = Overall),
    by = c("to" = "code")
  ) %>%
  mutate(OD_passenger = log(from_passenger) * log(to_passenger))
```

```{r frequency}
schedules <- read.csv("OctSchedules.txt", header = F)
freq <- read.csv("stations_freq.csv")
schedules <- schedules %>%
  dplyr::select(V1, V9, V10, V14) %>%
  rename(
    date = V1,
    arrive_time = V9,
    depart_time = V10,
    station = V14
  ) %>%
  mutate(time = ifelse(depart_time == "", arrive_time, depart_time)) %>%
  dplyr::select(-depart_time, -arrive_time) %>%
  mutate(date = dmy(date),
         datetime = as.POSIXct(paste(date, time), format = "%Y-%m-%d %H:%M:%S")) %>%
  dplyr::select(-date, -time) %>%
  left_join(freq %>% select(station, name), by = "station") %>%
  na.omit() %>%
  dplyr::select(-station) %>%
  left_join(stations %>% select(name, code), by = "name") %>%
  dplyr::select(-name)

start_date <- as.POSIXct("2016-10-23 00:00:00")

data <- data %>%
  mutate(
    mapped_date = as.Date(start_date) + ((as.numeric(
      as.Date(datetime_combined) - as.Date(start_date)
    )) %% 7),
    mapped_datetime = as.POSIXct(paste(
      mapped_date, format(datetime_combined, "%H:%M:%S")
    ), format = "%Y-%m-%d %H:%M:%S")
  )

data <- data %>%
  rowwise() %>%
  # mutate(
  #   freq_from = sum(
  #     schedules$datetime >= (mapped_datetime - hours(1)) &
  #       schedules$datetime <= (mapped_datetime + hours(1)) &
  #       schedules$code == from
  #   ),
  #   freq_to = sum(
  #     schedules$datetime >= (mapped_datetime - hours(1)) &
  #       schedules$datetime <= (mapped_datetime + hours(1)) &
  #       schedules$code == to
  #   ),
  #   freq = (freq_from + freq_to) / 2
  # ) %>%
  mutate(
    freq_from = sum(
      schedules$datetime >= (mapped_datetime - minutes(30)) &
        schedules$datetime <= (mapped_datetime + minutes(30)) &
        schedules$code == from
    ),
    freq_to = sum(
      schedules$datetime >= (mapped_datetime - minutes(30)) &
        schedules$datetime <= (mapped_datetime + minutes(30)) &
        schedules$code == to
    ),
    Frequency = (freq_from + freq_to) / 2
  ) %>%
  ungroup()
```

```{r type}
data <- data %>%
  mutate(type = case_when(
    type %in% c("ic") ~ "IC",
    type %in% c("ICT", "ICE", "THA", "TRN", "Extra") ~ "Other",
    TRUE ~ type
  ))
```

```{r weather}
weather <- read.csv('weather.csv')

weather <- weather %>%
  mutate(date = ymd(Time), month_day = format(date, "%m-%d"))

data <- data %>%
  mutate(month_day = format(date, "%m-%d")) %>%
  left_join(weather %>% select(month_day, Temperature, Precipitation), by = "month_day")
```

## 3. Exploratory data analysis

During our exploratory analysis of the datasets, we discovered that certain features had stronger correlations with train overcrowding (or lack thereof) than others.

Since the primary goal of this project is to identify trains with high occupancy, we merged the “medium” and “low” occupancy categories from the original dataset into a single “low” category, creating a binary variable suitable for logistic regression. Figure 1 illustrates the number of trains and the high occupancy rate daily during the data collection period. The observations are unevenly distributed, with most of the data concentrated after mid-September. Due to this characteristic, the high occupancy rate of trains was relatively unstable during the first half of the data collection period but stabilized at around 0.3 during the second half, without showing significant cyclical patterns.

```{r EDA occupancy}
occupancy.Panel <- data %>%
  group_by(date) %>%
  summarize(count = n(),
            high_occupancy_rate = mean(occupancy_classifier))

grid.arrange(
  arrangeGrob(
    ggplot(occupancy.Panel, aes(date, count)) + geom_line() +
      labs(title = "Count", x = "Date", y = "Count") + theme_minimal(),
    ggplot(occupancy.Panel, aes(date, high_occupancy_rate)) + geom_line() +
      labs(title = "High Occupancy Rate", x = "Date", y = "High Occupancy Rate") + theme_minimal(),
    ncol = 1
  ),
  bottom = textGrob(
    "Figure 1",
    x = 0.1,
    gp = gpar(fontsize = 10, fontface = "italic")
  )
)
```

From a temporal perspective, in Figure 2, we analyzed the impact of the hour of the day and the day of the week on the high occupancy rate of trains. It is evident that trains are more crowded during morning rush hours (6–8 AM) and the longer afternoon-evening rush hours on weekdays. High occupancy rates are particularly notable on Friday afternoons, Sunday afternoons, and Monday mornings, reflecting significant weekend travel demand.

```{r EDA temporal}
occupancy.Table <- data %>%
  group_by(dotw, hour) %>%
  summarize(
    count = n(),
    high_occupancy_rate = mean(occupancy_classifier, na.rm = TRUE)
  )

data_occupancy <- data %>%
  left_join(occupancy.Table, by = c("dotw", "hour"))

ggplot(data_occupancy %>% filter(count > 4),
       aes(x = dotw, y = hour, fill = high_occupancy_rate)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "firebrick") +
  labs(
    title = "High Occupancy Rate Across the Week",
    x = "Day of the Week",
    y = "Hour of the Day",
    fill = "High Occupancy Rate",
    caption = "Figure 2"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.caption = element_text(size = 10, face = "italic", hjust = 0)
  ) +
  scale_y_reverse()
```

From a spatial perspective, Figures 3 and 4 show the high occupancy rate distribution across stations and origin-destination (OD) pairs (filtered for data within Belgium). In Figure 4, the transparency of the lines represents the number of trains between the OD pairs in the data. Radial routes centered around Brussels and consecutive stations along certain peripheral routes display higher high occupancy rates.

```{r EDA spatial}
be <- st_read("be.shp", quiet = TRUE) %>% st_transform(crs = 4326)

ggplot(data = stations_sf %>% filter(!is.na(overall_avg))) +
  geom_sf(data = be,
          color = "white",
          alpha = 0.8) +
  geom_sf(aes(color = to_avg), size = 2) +
  scale_color_gradient(low = "grey80", high = "firebrick") +
  theme_minimal() +
  labs(
    title = "High Occupancy Rate by Station",
    color = "High Occupancy Rate",
    x = "Longitude",
    y = "Latitude",
    caption = "Figure 3"
  ) +
  theme(plot.caption = element_text(size = 10, face = "italic", hjust = 0))

od_data <- data %>%
  group_by(OD) %>%
  #filter(n() > 3) %>%
  summarize(
    count = n(),
    high_occupancy_rate = mean(occupancy_classifier, na.rm = TRUE),
    from = first(from),
    to = first(to)
  )

od_with_coords <- od_data %>%
  left_join(stations, by = c("from" = "code")) %>%
  rename(from_long = longitude, from_lat = latitude) %>%
  left_join(stations, by = c("to" = "code")) %>%
  rename(to_long = longitude, to_lat = latitude)

od_lines <- od_with_coords %>%
  filter(!is.na(from_long) & !is.na(to_long)) %>%
  rowwise() %>%
  mutate(geometry = st_sfc(st_linestring(matrix(
    c(from_long, from_lat, to_long, to_lat),
    ncol = 2,
    byrow = TRUE
  )), crs = 4326)) %>%
  st_as_sf()

ggplot() +
  geom_sf(data = be,
          color = "white",
          alpha = 0.5) +
  geom_sf(data = stations_sf,
          color = "black",
          size = 1.5) +
  geom_sf(
    data = od_lines,
    aes(color = high_occupancy_rate, alpha = count),
    linewidth = 1
  ) +
  scale_alpha(range = c(0.4, 1), guide = "legend") +
  scale_color_gradient(low = "grey80", high = "firebrick") +
  theme_minimal() +
  labs(
    title = "OD Connections with High Occupancy Rate",
    color = "High Occupancy Rate",
    alpha = "Count",
    x = "Longitude",
    y = "Latitude",
    caption = "Figure 4"
  ) +
  theme(plot.caption = element_text(size = 10, face = "italic", hjust = 0))
```

To enhance our analysis, we introduced additional variables. The distributions and correlations of these variables with occupancy are shown in Figures 5 through 7. InterCity trains accounted for the majority of the dataset, while other less common types were reclassified as “Others.” Peak trains exhibited the highest high occupancy rate, corresponding with the intuitive expectation of overcrowding during peak times. This was followed by InterCity trains, which primarily connect major cities, while local trains serving smaller towns had the lowest occupancy levels.

During the data collection period, temperatures were initially stable but began to drop from mid-September onwards, while precipitation was concentrated on a few specific days. Temperature was significantly negatively correlated with occupancy (p = 0.0045), whereas precipitation showed no significant correlation.

The largest stations recorded over 40,000 daily passengers, whereas most stations (59%) had fewer than 1,000. Due to the greater number of trains at larger stations, the histogram of daily passenger counts at origin/destination stations showed a U-shaped distribution. We found that the product of the logarithmic daily passenger counts of origin and destination stations was significantly positively correlated with occupancy (p = 0.0013). Therefore, we included it as a variable (“OD Passenger”) to describe the importance of the route.

We also referenced the complete dataset of trains (~278,000 records) over one week during the data collection period to calculate the number of trains passing through the origin and destination stations within 30 minutes before and after the train’s travel time. Since train schedules exhibit weekly periodicity, we adjusted the original dataset to align train trips with a reference week, reducing data processing time. Approximately half of the trips had fewer than 25 trains passing through their origin or destination stations within the 1-hour window. We averaged the values for the origin and destination stations and included them as a variable ("Frequency"), which was also significantly positively correlated with occupancy (p = 0.0003).

The feature distributions for occupancy emphasize these correlation characteristics. Higher density of high occupancy is more concentrated in lower temperature ranges and higher ranges of OD Passenger and Frequency. It is worth noting that although these three variables are significantly correlated with occupancy, their correlations are relatively weak, with absolute correlation coefficients between 0.06 and 0.08.

```{r EDA variables}
train_type <- data %>%
  group_by(type) %>%
  summarize(
    count = n(),
    high_occupancy_rate = mean(occupancy_classifier, na.rm = TRUE)
  )

weather.Panel <- data %>%
  group_by(date) %>%
  summarize(Temperature = max(Temperature),
            Precipitation = max(Precipitation))

grid.arrange(
  arrangeGrob(
    ggplot(train_type, aes(
      x = fct_reorder(type, count, .desc = TRUE), y = count
    )) +
      geom_col(
        position = position_dodge(width = 0.7),
        show.legend = FALSE,
        width = 0.7
      ) +
      labs(title = "Number of Trains by Train Type", x = "Train Type", y = "Number of Trains") +
      theme_minimal(),
    ggplot(train_type, aes(
      x = fct_reorder(type, count, .desc = TRUE), y = high_occupancy_rate
    )) +
      geom_col(
        position = position_dodge(width = 0.7),
        show.legend = FALSE,
        width = 0.7
      ) +
      labs(title = "High Occupancy Rate by Train Type", x = "Train Type", y = "High Occupancy Rate") +
      theme_minimal(),
    ggplot(weather.Panel, aes(date, Temperature)) + geom_line() +
      labs(title = "Temperature", x = "Day", y = "Temperature") + theme_minimal(),
    ggplot(weather.Panel, aes(date, Precipitation)) + geom_line() +
      labs(title = "Precipitation", x = "Day", y = "Precipitation") + theme_minimal(),
    ncol = 2,
    nrow = 2
  ),
  bottom = textGrob(
    "Figure 5",
    x = 0.1,
    gp = gpar(fontsize = 10, fontface = "italic")
  )
)

grid.arrange(
  arrangeGrob(
    ggplot(data, aes(x = from_passenger)) +
      geom_histogram(bins = 20) +
      labs(title = "Daily Passenger Count of Origins", x = "Passenger", y = "Frequency") +
      theme_minimal(),
    ggplot(data, aes(x = to_passenger)) +
      geom_histogram(bins = 20) +
      labs(title = "Daily Passenger Count of Destinations", x = "Passenger", y = "Frequency") +
      theme_minimal(),
    ggplot(data, aes(x = freq_from)) +
      geom_histogram(bins = 20) +
      labs(title = "One-hour Train Count of Origins", x = "Train", y = "Frequency") +
      theme_minimal(),
    ggplot(data, aes(x = freq_to)) +
      geom_histogram(bins = 20) +
      labs(title = "One-hour Train Count of Destinations", x = "Train", y = "Frequency") +
      theme_minimal(),
    ncol = 2,
    nrow = 2
  ),
  bottom = textGrob(
    "Figure 6",
    x = 0.1,
    gp = gpar(fontsize = 10, fontface = "italic")
  )
)

data %>%
  dplyr::select(occupancy_classifier,
                Temperature,
                Precipitation,
                OD_passenger,
                Frequency) %>%
  gather(Variable, value, -occupancy_classifier) %>%
  mutate(Variable = factor(
    Variable,
    levels = c("Temperature", "Precipitation", "OD_passenger", "Frequency")
  )) %>%
  ggplot() +
  geom_density(aes(value, color = as.factor(occupancy_classifier)), fill = "transparent") +
  facet_wrap(~ Variable, scales = "free") +
  scale_color_manual(values = c("firebrick", "skyblue4")) +
  labs(title = "Feature Distributions of Occupancy",
       color = "Occupancy Classifier",
       caption = "Figure 7") +
  theme(plot.caption = element_text(size = 10, face = "italic", hjust = 0))
```

## 4. Logistic regression

We used logistic regression for modeling, with the binary variable “Occupancy Classifier” (1 for high occupancy, 0 for low occupancy) as the dependent variable, aiming to distinguish trains with high occupancy rates.

Our baseline “business as usual” model included only three variables from the original dataset: train type, hour of the day, and day of the week. Aggregating data into hourly units ensured sufficient data density in each interval while improving their differentiation.

We initially experimented with grouping temporal variables by day/hour to reflect occupancy’s periodic patterns (e.g., Monday morning or Saturday evening) and grouping spatial variables (i.e., OD pairs) by passenger counts (e.g., large station to medium station). However, these approaches yielded limited improvements to the model. Through continued exploration, we identified two significant variables, OD Passenger and Frequency, and included them alongside the significant variable Temperature, but the results were still unsatisfactory.

```{r sets}
data_model <- data %>% dplyr::select(
  occupancy_classifier,
  from,
  to,
  datetime_combined,
  hour,
  dotw,
  type,
  Temperature,
  Precipitation,
  OD_passenger,
  Frequency
) %>%
  mutate(dotw = as.character(dotw), hour = as.factor(hour))

set.seed(888)
trainIndex <- createDataPartition(
  data_model$occupancy_classifier,
  p = 0.7,
  list = FALSE,
  times = 1
)

dataTrain <- data_model[trainIndex, ]
dataTest <- data_model[-trainIndex, ]
```

To better utilize the spatial and temporal characteristics of the dataset, we incorporated a nearest-neighbor approach. For each observation, we calculated the high occupancy rate of the five nearest (including the current) stations from the origin/destination and averaged the rates to estimate occupancy (“OD neighbor” variable). Temporally, we aggregated the dataset into a single week and calculated the high occupancy rate of the 20 closest trains by travel time for each observation (“Adjacent” variable). The optimal values of k were determined through trials. In a randomly selected training set, both variables were significantly positively correlated with occupancy, with correlation coefficients of 0.16 and 0.33, respectively. Including these variables substantially improved the model's explanatory and predictive power.

We used cross-validation to evaluate the model’s accuracy and generalizability, splitting the dataset into 70% for training and 30% for testing. The training set was used to fit the model, while the testing set was used to optimize the threshold and evaluate model performances.

Since OD neighbor and Adjacent were derived from the existing occupancy data, they were generated after the training/test split. For each random sampling, this generation process was repeated for the new sets.

```{r nearest neighbor}
from_sum <- dataTrain %>%
  group_by(from) %>%
  summarize(from_count = n(),
            from_sum = sum(occupancy_classifier, na.rm = TRUE))

to_sum <- dataTrain %>%
  group_by(to) %>%
  summarize(to_count = n(),
            to_sum = sum(occupancy_classifier, na.rm = TRUE))

stations_train <- stations_sf[, c(1, 12)] %>%
  left_join(from_sum, by = c("code" = "from")) %>%
  left_join(to_sum, by = c("code" = "to")) %>%
  replace(is.na(.), 0) %>%
  mutate(overall_count = from_count + to_count,
         overall_sum = from_sum + to_sum)

coords <- st_coordinates(stations_train)

knn_nb <- knn2nb(knearneigh(coords, k = 5))

neighbor_results <- lapply(1:length(knn_nb), function(i) {
  neighbors <- knn_nb[[i]]
  
  overall_count_sum <- sum(stations_train$overall_count[neighbors], na.rm = TRUE)
  overall_sum_sum <- sum(stations_train$overall_sum[neighbors], na.rm = TRUE)
  
  return(
    data.frame(overall_count_sum = overall_count_sum, overall_sum_sum = overall_sum_sum)
  )
})

neighbor_results_df <- do.call(rbind, neighbor_results)

stations_train <- stations_train %>%
  bind_cols(neighbor_results_df) %>%
  mutate(neighbor = overall_sum_sum / overall_count_sum) %>%
  st_drop_geometry()

dataTrain <- dataTrain %>%
  left_join(
    stations_train %>% select(code, neighbor) %>% rename(from_neighbor = neighbor),
    by = c("from" = "code")
  ) %>%
  left_join(
    stations_train %>% select(code, neighbor) %>% rename(to_neighbor = neighbor),
    by = c("to" = "code")
  ) %>%
  mutate(OD_neighbor = (from_neighbor + to_neighbor) / 2) 
```

```{r nearest trains}
dataTrain <- dataTrain %>%
  mutate(
    mapped_date = as.Date(start_date) + ((as.numeric(
      as.Date(datetime_combined) - as.Date(start_date)
    )) %% 7),
    mapped_datetime = as.POSIXct(paste(
      mapped_date, format(datetime_combined, "%H:%M:%S")
    ), format = "%Y-%m-%d %H:%M:%S")
  )

datetime <- dataTrain %>%
  dplyr::select(occupancy_classifier, datetime_combined, mapped_datetime) %>%
  arrange(mapped_datetime) %>%
  slice(1:20) %>%
  mutate(mapped_datetime = mapped_datetime + days(7)) %>%
  bind_rows(
    dataTrain %>%
      dplyr::select(occupancy_classifier, datetime_combined, mapped_datetime) %>%
      arrange(mapped_datetime) %>%
      slice((n() - 19):n()) %>%
      mutate(mapped_datetime = mapped_datetime - days(7))
  ) %>%
  bind_rows(
    dataTrain %>%
      dplyr::select(occupancy_classifier, datetime_combined, mapped_datetime)
  )

datetime <- datetime %>%
  arrange(mapped_datetime)

dataTrain <- dataTrain %>%
  mutate(Adjacent = map_dbl(1:n(), function(i) {
    distances <- abs(as.numeric(datetime$mapped_datetime - mapped_datetime[i]))
    nearest_indices <- order(distances)[1:20]
    mean(datetime$occupancy_classifier[nearest_indices], na.rm = TRUE)
  }))
```

The logistic regression results are shown in Table 1. As expected, OD neighbor and Adjacent were the most significant predictors, while OD Passenger and Frequency were also significant. Notably, Frequency showed a negative correlation in the model, indicating that controlling other variables, an increase in train frequency reduced overcrowding. However, when considered solely, higher frequency often coincides with peak times, leading to a positive correlation, which fits our intuition. Regarding train type, compared to InterCity trains, Local and Peak trains showed marginal significance in opposite directions, while Temperature also showed a similar marginal significance.

```{r model}
model <- glm(
  occupancy_classifier ~ type + Temperature + OD_passenger + Frequency + OD_neighbor + Adjacent,
  data = dataTrain,
  family = "binomial" (link = "logit")
)

model_summary <- tidy(model) %>%
  mutate(
    significance = case_when(
      p.value < 0.001 ~ "***",
      p.value < 0.01 ~ "**",
      p.value < 0.05 ~ "*",
      p.value < 0.1 ~ ".",
      TRUE ~ ""
    )
  ) %>%
  select(term, estimate, p.value, significance) %>%
  rename(
    Variable = term,
    Coefficient = estimate,
    P_Value = p.value,
    Sig. = significance
  )

descriptions <- tibble(
  Variable = c(
    "(Intercept)",
    "typeL",
    "typeOther",
    "typeP",
    "typeS",
    "Temperature",
    "OD_passenger",
    "Frequency",
    "OD_neighbor",
    "Adjacent"
  ),
  Description = c(
    "",
    "Includes InterCity (IC), Local (L), Peak (P), Suburban (S), and other types (combined due to lower counts) of trains. Extracted from the 'vehicle' column in the original dataset.",
    "",
    "",
    "",
    "The average temperature in Brussels on the day. Sourced from Weather and Climate.",
    "The product of the logarithm of average daily passenger flow at origin and destination stations. Computed using passenger count data from SNCB (2023).",
    "The average number of trains passing through the origin and destination stations within 30 minutes before and after the train's travel time. Computed using punctuality data from Open Data Wallonie-Bruxelles.",
    "The average High Occupancy Rate of the five nearest stations of the origin and destination (included) stations. Computed using station location information extracted from the stations dataset.",
    "The High Occupancy Rate of the 20 trains closest in time to the train's travel time, within a week-integrated dataset. Computed using time information extracted from the original dataset."
  )
)

model_summary <- model_summary %>%
  left_join(descriptions, by = "Variable")

kable(model_summary,
      format = "markdown",
      digits = 4,
      caption = "Table 1: Summary of the Logistic Regression Model")
```

## 5. Goodness of fit

```{r test}
dataTest <- dataTest %>%
  left_join(
    stations_train %>% select(code, neighbor) %>% rename(from_neighbor = neighbor),
    by = c("from" = "code")
  ) %>%
  left_join(
    stations_train %>% select(code, neighbor) %>% rename(to_neighbor = neighbor),
    by = c("to" = "code")
  ) %>%
  mutate(OD_neighbor = (from_neighbor + to_neighbor) / 2)

dataTest <- dataTest %>%
  mutate(
    mapped_date = as.Date(start_date) + ((as.numeric(
      as.Date(datetime_combined) - as.Date(start_date)
    )) %% 7),
    mapped_datetime = as.POSIXct(paste(
      mapped_date, format(datetime_combined, "%H:%M:%S")
    ), format = "%Y-%m-%d %H:%M:%S")
  )

dataTest <- dataTest %>%
  mutate(Adjacent = map_dbl(1:n(), function(i) {
    distances <- abs(as.numeric(datetime$mapped_datetime - mapped_datetime[i]))
    nearest_indices <- order(distances)[1:20]
    mean(datetime$occupancy_classifier[nearest_indices], na.rm = TRUE)
  }))

dataTest <- dataTest %>%
  mutate(occupancy_classifier = factor(
    occupancy_classifier,
    levels = c(0, 1),
    labels = c("Low", "High")
  ))

testProbs <- data.frame(
  Outcome = dataTest$occupancy_classifier,
  Probs = predict(model, dataTest, type = "response")
)
```

We evaluated model performance using the ROC curve (AUC), accuracy, sensitivity, and specificity. Figure 7 shows the ROC curve based on the test set, illustrating the trade-off between true positive and false positive rates as the classification threshold changes. The AUC value exceeds 0.5 as the curve lies above the y = x line, indicating that it has predictive ability to some extent.

```{r ROC}
auc_value <- auc(testProbs$Outcome, testProbs$Probs)

ggplot(testProbs, aes(d = as.numeric(Outcome), m = Probs)) +
  geom_roc(n.cuts = 50,
           labels = FALSE,
           colour = "skyblue4") +
  style_roc(theme = theme_grey) +
  geom_abline(
    slope = 1,
    intercept = 0,
    linewidth = 1,
    color = 'grey'
  ) +
  geom_text(
    aes(
      x = 0,
      y = 0.9,
      label = paste("AUC:", round(auc_value, 4))
    ),
    colour = "black",
    size = 4,
    hjust = 0
  ) +
  labs(title = "ROC Curve", caption = "Figure 9") +
  theme(plot.caption = element_text(size = 10, face = "italic", hjust = 0))
```

## 6. Cost-benefit analysis

To determine the optimal threshold for high/low occupancy classification, we developed a simple cost-benefit analysis model, as shown in Table 2. Incorporating passenger experiences, we used “Utility” instead of “Revenue” to measure the potential benefits of applying the model. Negative predictions (low occupancy) resulted in zero utility since they lead to no schedule adjustments. Positive predictions (high occupancy) resulted in schedule adjustments. For true positives, avoiding discomfort and delays after schedule optimization yielded a utility of 2, while false positives incurred a utility of -1 due to the cost of deploying additional trains. This matrix reflects our prioritization of user experience over infrastructure investment, though the real-world model may differ. Implications of our cost-benefit-analysis approach will be explained later in our analysis reflection. 

```{r cost benefit}
confusion_matrix_table <- data.frame(
  "Condition" = c(
    "True Positive",
    "False Positive",
    "True Negative",
    "False Negative"
  ),
  "Description" = c(
    "Predicted overcrowded and train is overcrowded",
    "Predicted overcrowded and train is not overcrowded",
    "Predicted not overcrowded and train is not overcrowded",
    "Predicted not overcrowded but train is overcrowded"
  ),
  "Utility" = c(
    "2: Discomfort and delay avoided by optimization",
    "-1: Cost of sending additional trains out",
    "0",
    "0"
  )
)

kable(
  confusion_matrix_table,
  format = "markdown",
  col.names = c("Condition", "Description", "Utility"),
  caption = "Table 2: Cost-Benefit Analysis"
)
```

By testing different thresholds, we calculated utility and identified the optimal threshold at 0.32, where utility peaked, as shown in Figure 9. Using this threshold, the model achieved an accuracy of 0.6109, sensitivity of 0.5143, and specificity of 0.6562. Since the dataset was imbalanced (low occupancy rates were much higher than high occupancy rates), improving sensitivity required sacrificing accuracy. Compared to random guessing (31% high occupancy rate), the model significantly improved the identification of high occupancy trains. Although the improvement was modest, it demonstrated that the model could still provide valuable information for transportation planners to optimize schedules.

```{r threshold}
iterateThresholds <- function(data) {
  x = .01
  all_prediction <- data.frame()
  while (x <= 1) {
    this_prediction <-
      testProbs %>%
      mutate(predOutcome = ifelse(Probs > x, "High", "Low")) %>%
      count(predOutcome, Outcome) %>%
      summarize(
        True_Negative = sum(n[predOutcome == "Low" & Outcome == "Low"]),
        True_Positive = sum(n[predOutcome == "High" &
                                Outcome == "High"]),
        False_Negative = sum(n[predOutcome == "Low" &
                                 Outcome == "High"]),
        False_Positive = sum(n[predOutcome == "High" &
                                 Outcome == "Low"])
      ) %>%
      gather(Variable, Count) %>%
      mutate(
        Utility =
          ifelse(
            Variable == "True_Negative",
            0 * Count,
            ifelse(
              Variable == "True_Positive",
              2 * Count,
              ifelse(
                Variable == "False_Negative",
                0 * Count,
                ifelse(Variable == "False_Positive", (-1) * Count, 0)
              )
            )
          ),
        Threshold = x
      )
    
    all_prediction <- rbind(all_prediction, this_prediction)
    x <- x + .01
  }
  return(all_prediction)
}

whichThreshold <- iterateThresholds(testProbs)

whichThreshold_utility <-
  whichThreshold %>%
  group_by(Threshold) %>%
  summarize(Utility = sum(Utility))

optimal_threshold <- whichThreshold_utility %>%
  filter(Utility == max(Utility)) %>%
  pull(Threshold)

ggplot(whichThreshold_utility) +
  geom_line(aes(x = Threshold, y = Utility),
            color = "skyblue4",
            size = 1) +
  geom_vline(
    xintercept = pull(arrange(whichThreshold_utility, -Utility)[1, 1]),
    color = "firebrick",
    size = 1,
    linetype = 3
  ) +
  annotate(
    "text",
    x = optimal_threshold[1],
    y = 0,
    label = paste("Optimal Threshold:", optimal_threshold[1]),
    hjust = -0.1,
    vjust = -0.5,
    color = "black",
    size = 4
  ) +
  labs(title = "Model Utilities By Threshold For Test Set",
       subtitle = "Vertical Line Denotes Optimal Threshold",
       caption = "Figure 9") +
  theme(plot.caption = element_text(size = 10, face = "italic", hjust = 0))
```

```{r confusion matrix, include=TRUE}
threshold <- optimal_threshold

testProbs <- testProbs %>%
  mutate(
    Predicted = ifelse(Probs >= threshold, "High", "Low"),
    Predicted = factor(Predicted, levels = c("Low", "High"))
  )

confusion_matrix <- confusionMatrix(testProbs$Predicted, testProbs$Outcome, positive = "High")

accuracy <- round(confusion_matrix$overall["Accuracy"], 4)
sensitivity <- round(confusion_matrix$byClass["Sensitivity"], 4)
specificity <- round(confusion_matrix$byClass["Specificity"], 4)

cat(
  "Accuracy:",
  accuracy,
  "Sensitivity:",
  sensitivity,
  "Specificity:",
  specificity,
  "\n"
)
```

## 7. Cross validation

To reduce the instability of single-run predictions, we repeated the above process (splitting the dataset, fitting the model) 100 times to determine the optimal threshold, then repeated it another 100 times to calculate AUC, sensitivity, and specificity. Figure 10 shows the distributions of these metrics over 100 runs. Results show that AUC was consistently above 0.5, indicating the model outperformed random guessing. However, sensitivity and optimal threshold have high variances, reflecting the challenges of modeling occupancy influenced by complex real-world patterns. Ultimately, the model achieved an average sensitivity of 0.5405 and specificity of 0.6376, slightly better than the initial simulation.

```{r repitition threshold}
thresholds <- list()

for (i in 1:100) {
  set.seed(888 + i)
  trainIndex <- createDataPartition(
    data_model$occupancy_classifier,
    p = 0.7,
    list = FALSE,
    times = 1
  )
  
  dataTrain <- data_model[trainIndex, ]
  dataTest <- data_model[-trainIndex, ]
  
  from_sum <- dataTrain %>%
    group_by(from) %>%
    summarize(from_count = n(),
              from_sum = sum(occupancy_classifier, na.rm = TRUE))
  
  to_sum <- dataTrain %>%
    group_by(to) %>%
    summarize(to_count = n(),
              to_sum = sum(occupancy_classifier, na.rm = TRUE))
  
  stations_train <- stations_sf[, c(1, 12)] %>%
    left_join(from_sum, by = c("code" = "from")) %>%
    left_join(to_sum, by = c("code" = "to")) %>%
    replace(is.na(.), 0) %>%
    mutate(overall_count = from_count + to_count,
           overall_sum = from_sum + to_sum)
  
  coords <- st_coordinates(stations_train)
  
  knn_nb <- knn2nb(knearneigh(coords, k = 5))
  
  neighbor_results <- lapply(1:length(knn_nb), function(i) {
    neighbors <- knn_nb[[i]]
    
    overall_count_sum <- sum(stations_train$overall_count[neighbors], na.rm = TRUE)
    overall_sum_sum <- sum(stations_train$overall_sum[neighbors], na.rm = TRUE)
    
    return(
      data.frame(
        overall_count_sum = overall_count_sum,
        overall_sum_sum = overall_sum_sum
      )
    )
  })
  
  neighbor_results_df <- do.call(rbind, neighbor_results)
  
  stations_train <- stations_train %>%
    bind_cols(neighbor_results_df) %>%
    mutate(neighbor = overall_sum_sum / overall_count_sum) %>%
    st_drop_geometry()
  
  dataTrain <- dataTrain %>%
    left_join(
      stations_train %>% select(code, neighbor) %>% rename(from_neighbor = neighbor),
      by = c("from" = "code")
    ) %>%
    left_join(
      stations_train %>% select(code, neighbor) %>% rename(to_neighbor = neighbor),
      by = c("to" = "code")
    ) %>%
    mutate(OD_neighbor = (from_neighbor + to_neighbor) / 2)
  
  dataTrain <- dataTrain %>%
    mutate(
      mapped_date = as.Date(start_date) + ((as.numeric(
        as.Date(datetime_combined) - as.Date(start_date)
      )) %% 7),
      mapped_datetime = as.POSIXct(paste(
        mapped_date, format(datetime_combined, "%H:%M:%S")
      ), format = "%Y-%m-%d %H:%M:%S")
    )
  
  datetime <- dataTrain %>%
    dplyr::select(occupancy_classifier, datetime_combined, mapped_datetime) %>%
    arrange(mapped_datetime) %>%
    slice(1:20) %>%
    mutate(mapped_datetime = mapped_datetime + days(7)) %>%
    bind_rows(
      dataTrain %>%
        dplyr::select(occupancy_classifier, datetime_combined, mapped_datetime) %>%
        arrange(mapped_datetime) %>%
        slice((n() - 19):n()) %>%
        mutate(mapped_datetime = mapped_datetime - days(7))
    ) %>%
    bind_rows(
      dataTrain %>%
        dplyr::select(occupancy_classifier, datetime_combined, mapped_datetime)
    )
  
  datetime <- datetime %>%
    arrange(mapped_datetime)
  
  dataTrain <- dataTrain %>%
    mutate(Adjacent = map_dbl(1:n(), function(i) {
      distances <- abs(as.numeric(datetime$mapped_datetime - mapped_datetime[i]))
      nearest_indices <- order(distances)[1:20]
      mean(datetime$occupancy_classifier[nearest_indices], na.rm = TRUE)
    }))
  
  model <- glm(
    occupancy_classifier ~ type + Temperature + OD_passenger + Frequency + OD_neighbor + Adjacent,
    data = dataTrain,
    family = "binomial" (link = "logit")
  )
  
  dataTest <- dataTest %>%
    left_join(
      stations_train %>% select(code, neighbor) %>% rename(from_neighbor = neighbor),
      by = c("from" = "code")
    ) %>%
    left_join(
      stations_train %>% select(code, neighbor) %>% rename(to_neighbor = neighbor),
      by = c("to" = "code")
    ) %>%
    mutate(OD_neighbor = (from_neighbor + to_neighbor) / 2)
  
  dataTest <- dataTest %>%
    mutate(
      mapped_date = as.Date(start_date) + ((as.numeric(
        as.Date(datetime_combined) - as.Date(start_date)
      )) %% 7),
      mapped_datetime = as.POSIXct(paste(
        mapped_date, format(datetime_combined, "%H:%M:%S")
      ), format = "%Y-%m-%d %H:%M:%S")
    )
  
  dataTest <- dataTest %>%
    mutate(Adjacent = map_dbl(1:n(), function(i) {
      distances <- abs(as.numeric(datetime$mapped_datetime - mapped_datetime[i]))
      nearest_indices <- order(distances)[1:20]
      mean(datetime$occupancy_classifier[nearest_indices], na.rm = TRUE)
    }))
  
  dataTest <- dataTest %>%
    mutate(occupancy_classifier = factor(
      occupancy_classifier,
      levels = c(0, 1),
      labels = c("Low", "High")
    ))
  
  testProbs <- data.frame(
    Outcome = as.factor(dataTest$occupancy_classifier),
    Probs = predict(model, dataTest, type = "response")
  )
  
  iterateThresholds <- function(data) {
    x = .01
    all_prediction <- data.frame()
    while (x <= 1) {
      this_prediction <-
        testProbs %>%
        mutate(predOutcome = ifelse(Probs > x, "High", "Low")) %>%
        count(predOutcome, Outcome) %>%
        summarize(
          True_Negative = sum(n[predOutcome == "Low" & Outcome == "Low"]),
          True_Positive = sum(n[predOutcome == "High" &
                                  Outcome == "High"]),
          False_Negative = sum(n[predOutcome == "Low" &
                                   Outcome == "High"]),
          False_Positive = sum(n[predOutcome == "High" &
                                   Outcome == "Low"])
        ) %>%
        gather(Variable, Count) %>%
        mutate(
          Utility =
            ifelse(
              Variable == "True_Negative",
              0 * Count,
              ifelse(
                Variable == "True_Positive",
                2 * Count,
                ifelse(
                  Variable == "False_Negative",
                  0 * Count,
                  ifelse(Variable == "False_Positive", (-1) * Count, 0)
                )
              )
            ),
          Threshold = x
        )
      
      all_prediction <- rbind(all_prediction, this_prediction)
      x <- x + .01
    }
    return(all_prediction)
  }
  
  whichThreshold <- iterateThresholds(testProbs)
  
  whichThreshold_utility <-
    whichThreshold %>%
    group_by(Threshold) %>%
    summarize(Utility = sum(Utility))
  
  optimal_threshold <- whichThreshold_utility %>%
    filter(Utility == max(Utility)) %>%
    pull(Threshold)
  
  thresholds[[i]] <- list(optimal_threshold = optimal_threshold)
  
  # cat("Iteration:", i, "Optimal Threshold:", optimal_threshold, "\n")
}

avg_optimal_threshold <- mean(sapply(thresholds, function(res) res$optimal_threshold[1]), na.rm = T)
# cat("Average Optimal Threshold over 100 runs:", avg_optimal_threshold, "\n")
```

```{r repitition metrics}
results <- list()

for (i in 1:100) {
  set.seed(1000 + i)
  trainIndex <- createDataPartition(
    data_model$occupancy_classifier,
    p = 0.7,
    list = FALSE,
    times = 1
  )
  
  dataTrain <- data_model[trainIndex, ]
  dataTest <- data_model[-trainIndex, ]
  
  from_sum <- dataTrain %>%
    group_by(from) %>%
    summarize(from_count = n(),
              from_sum = sum(occupancy_classifier, na.rm = TRUE))
  
  to_sum <- dataTrain %>%
    group_by(to) %>%
    summarize(to_count = n(),
              to_sum = sum(occupancy_classifier, na.rm = TRUE))
  
  stations_train <- stations_sf[, c(1, 12)] %>%
    left_join(from_sum, by = c("code" = "from")) %>%
    left_join(to_sum, by = c("code" = "to")) %>%
    replace(is.na(.), 0) %>%
    mutate(overall_count = from_count + to_count,
           overall_sum = from_sum + to_sum)
  
  coords <- st_coordinates(stations_train)
  
  knn_nb <- knn2nb(knearneigh(coords, k = 5))
  
  neighbor_results <- lapply(1:length(knn_nb), function(i) {
    neighbors <- knn_nb[[i]]
    
    overall_count_sum <- sum(stations_train$overall_count[neighbors], na.rm = TRUE)
    overall_sum_sum <- sum(stations_train$overall_sum[neighbors], na.rm = TRUE)
    
    return(
      data.frame(
        overall_count_sum = overall_count_sum,
        overall_sum_sum = overall_sum_sum
      )
    )
  })
  
  neighbor_results_df <- do.call(rbind, neighbor_results)
  
  stations_train <- stations_train %>%
    bind_cols(neighbor_results_df) %>%
    mutate(neighbor = overall_sum_sum / overall_count_sum) %>%
    st_drop_geometry()
  
  dataTrain <- dataTrain %>%
    left_join(
      stations_train %>% select(code, neighbor) %>% rename(from_neighbor = neighbor),
      by = c("from" = "code")
    ) %>%
    left_join(
      stations_train %>% select(code, neighbor) %>% rename(to_neighbor = neighbor),
      by = c("to" = "code")
    ) %>%
    mutate(OD_neighbor = (from_neighbor + to_neighbor) / 2)
  
  dataTrain <- dataTrain %>%
    mutate(
      mapped_date = as.Date(start_date) + ((as.numeric(
        as.Date(datetime_combined) - as.Date(start_date)
      )) %% 7),
      mapped_datetime = as.POSIXct(paste(
        mapped_date, format(datetime_combined, "%H:%M:%S")
      ), format = "%Y-%m-%d %H:%M:%S")
    )
  
  datetime <- dataTrain %>%
    dplyr::select(occupancy_classifier, datetime_combined, mapped_datetime) %>%
    arrange(mapped_datetime) %>%
    slice(1:20) %>%
    mutate(mapped_datetime = mapped_datetime + days(7)) %>%
    bind_rows(
      dataTrain %>%
        dplyr::select(occupancy_classifier, datetime_combined, mapped_datetime) %>%
        arrange(mapped_datetime) %>%
        slice((n() - 19):n()) %>%
        mutate(mapped_datetime = mapped_datetime - days(7))
    ) %>%
    bind_rows(
      dataTrain %>%
        dplyr::select(occupancy_classifier, datetime_combined, mapped_datetime)
    )
  
  datetime <- datetime %>%
    arrange(mapped_datetime)
  
  dataTrain <- dataTrain %>%
    mutate(Adjacent = map_dbl(1:n(), function(i) {
      distances <- abs(as.numeric(datetime$mapped_datetime - mapped_datetime[i]))
      nearest_indices <- order(distances)[1:20]
      mean(datetime$occupancy_classifier[nearest_indices], na.rm = TRUE)
    }))
  
  model <- glm(
    occupancy_classifier ~ type + Temperature + OD_passenger + Frequency + OD_neighbor + Adjacent,
    data = dataTrain,
    family = "binomial" (link = "logit")
  )
  
  dataTest <- dataTest %>%
    left_join(
      stations_train %>% select(code, neighbor) %>% rename(from_neighbor = neighbor),
      by = c("from" = "code")
    ) %>%
    left_join(
      stations_train %>% select(code, neighbor) %>% rename(to_neighbor = neighbor),
      by = c("to" = "code")
    ) %>%
    mutate(OD_neighbor = (from_neighbor + to_neighbor) / 2)
  
  dataTest <- dataTest %>%
    mutate(
      mapped_date = as.Date(start_date) + ((as.numeric(
        as.Date(datetime_combined) - as.Date(start_date)
      )) %% 7),
      mapped_datetime = as.POSIXct(paste(
        mapped_date, format(datetime_combined, "%H:%M:%S")
      ), format = "%Y-%m-%d %H:%M:%S")
    )
  
  dataTest <- dataTest %>%
    mutate(Adjacent = map_dbl(1:n(), function(i) {
      distances <- abs(as.numeric(datetime$mapped_datetime - mapped_datetime[i]))
      nearest_indices <- order(distances)[1:20]
      mean(datetime$occupancy_classifier[nearest_indices], na.rm = TRUE)
    }))
  
  dataTest <- dataTest %>%
    mutate(occupancy_classifier = factor(
      occupancy_classifier,
      levels = c(0, 1),
      labels = c("Low", "High")
    ))
  
  testProbs <- data.frame(
    Outcome = as.factor(dataTest$occupancy_classifier),
    Probs = predict(model, dataTest, type = "response")
  )
  
  auc_value <- auc(testProbs$Outcome, testProbs$Probs)
  
  threshold <- avg_optimal_threshold
  
  testProbs <- testProbs %>%
    mutate(
      Predicted = ifelse(Probs >= threshold, "High", "Low"),
      Predicted = factor(Predicted, levels = c("Low", "High"))
    )
  
  
  confusion_matrix <- confusionMatrix(testProbs$Predicted, testProbs$Outcome, positive = "High")
  
  sensitivity <- confusion_matrix$byClass["Sensitivity"]
  specificity <- confusion_matrix$byClass["Specificity"]
  
  results[[i]] <- list(auc_value = auc_value,
                       sensitivity = sensitivity,
                       specificity = specificity)
  
  # cat("Iteration:", i, "AUC Value:", round(auc_value, 4), "Sensitivity:", round(sensitivity, 4),
  #     "Specificity:", round(specificity, 4), "\n")
}

# avg_auc_value <- mean(sapply(results, function(res) res$auc_value), na.rm = T)
# avg_sensitivity <- mean(sapply(results, function(res) res$sensitivity))
# avg_specificity <- mean(sapply(results, function(res) res$specificity))
#
# cat("Average AUC Value over 100 runs:", round(avg_auc_value, 4), "\n")
# cat("Average Sensitivity over 100 runs:", round(avg_sensitivity, 4), "\n")
# cat("Average Specificity over 100 runs:", round(avg_specificity, 4), "\n")
```

In 100 simulations, the improved model outperformed the “business as usual” model (which included only train type, hour of the day, and day of the week) in average utility. The improved model raised the utility from 69.28 to 72.48, an approximate 4.6% increase, showing a relatively notable improvement. This demonstrates that the model performs better than the traditional methods employed by transportation planners, providing practical insights to reduce overcrowding.

```{r plot, include=TRUE}
metrics_data <- data.frame(
  Threshold = sapply(thresholds, function(x)
    x$optimal_threshold[1]),
  AUC_Value = sapply(results, function(x)
    x$auc_value),
  Sensitivity = sapply(results, function(x)
    x$sensitivity),
  Specificity = sapply(results, function(x)
    x$specificity)
)

metrics_long <- metrics_data %>%
  gather(key = "metric", value = "value") %>%
  mutate(metric = factor(
    metric,
    levels = c("AUC_Value", "Threshold", "Sensitivity", "Specificity")
  ))

metrics_means <- metrics_long %>%
  group_by(metric) %>%
  summarize(mean = mean(value))

metrics_long %>%
  left_join(metrics_means, by = "metric") %>%
  ggplot(aes(value)) +
  geom_histogram(bins = 20, fill = "skyblue4") +
  facet_wrap(~ metric, scales = "free") +
  geom_vline(
    aes(xintercept = mean),
    colour = "firebrick",
    linetype = 3,
    size = 1
  ) +
  labs(
    x = "Metric Value",
    y = "Count",
    title = "Simulation Metrics Distributions",
    subtitle = "Dotted lines represent the mean value",
    caption = "Figure 10"
  ) +
  theme_minimal() +
  theme(
    plot.caption = element_text(size = 10, face = "italic", hjust = 0),
    strip.text = element_text(face = "bold")
  )

metrics_means %>%
  rowwise() %>%
  mutate(output = paste("Average", metric, "over 100 runs:", round(mean, 4))) %>%
  pull(output) %>%
  cat(sep = "\n")
```

## 8. Discussion and conclusion

Our analysis meets the use case we set to address by allowing Belgian transportation planners to forecast train occupancy months in advance and allowing them to change schedules to minimize potential overcrowding. It has a wide variety of input data, which allows for a large degree of customizability for transportation planners. They would, theoretically, input weeks worth of schedules in our model and get results. Even so, we realize that forecasting far in advance is difficult. There are many variables that can change. The Covid-19 pandemic showed that even traditional 9-5 working patterns can be fundamentally disrupted. Our model’s less-than-optimal sensitivity of 0.507, and promising specificity of 0.667 shows the difficulty behind making scheduling predictions. In that sense, when purely considering our cost-benefit analysis of train overcrowding, our model does not do an optimal job at maximizing true positives. Our model does perform better in terms of specificity or the true negative rate. However, even this rate could see improvements. In that light, the model we created may not be as exceptional at predicting overcrowding as we would like. That said, it is still useful for transportation planners. Our ROC curve demonstrates that the model does actually perform better than a coin toss (with an ROC of 0.607), which is essentially what transportation planners are doing now (or rather an educated guess). While the educated guess method may have worked in the past, we believe that recent history has shown that this method has severe flaws. Our analysis outperformed the “business as usual” case in every simulation we ran, and that was with our “business as usual case” simulation representing a more analytical approach to current transportation planning than reality (where reality involves more human analysis, rather than data-based modeling). We set out to help predict high occupancy trains better than the current methodology, and our model does that. However, we acknowledge that there are serious flaws in the model that could be flushed out and that the lack of input data regarding overcrowding hampered our ability to make accurate predictions. Even so, we believe that the model methodology is still a sound way to solve for overcrowding on Belgian trains. 

We believe that the original dataset we worked with presented a significant challenge for us. The dataset on train occupancy characteristics contained a small (and varied) sample set of trains. For instance, certain months (mainly August and early September) seemed to have far fewer trains than in October (which is not the case in reality). That is because the dataset was an incomplete picture of trains in Belgium and thus an incomplete picture of occupancy. If we had a complete picture of train occupancy throughout the entire year (rather than a small sample dataset) we believe that our model would be more accurate. Moreover, the months present in the dataset only contained one public holiday, so the generalizability of the model to other timeframes with holidays would be poor. Obtaining a dataset with the full year of occupancy would also mean that we would obtain a full year of temperature data and a full picture of train scheduling. While we were able to attain the associated train frequency per station within the time frame of the dataset, an in-depth schedule by train run would be a better determiner of frequency. Our model’s issues with accuracy, sensitivity, and specificity, would be greatly helped with a complete dataset picture. 

We also believe that coordination with SNCB to create a more accurate and useful cost-benefit analysis is paramount. Our current cost-benefit analysis is missing much of the detail necessary for SNCB planners to understand the impact of overcrowding on the system or the cost of adding new trains to combat overcrowding. For instance, we would like to collect data on the cost of servicing additional trains, the cost of operators per additional train, and the cost of additional maintenance on running more trains (both in terms of per train and systemwide). We would also like to know the relative importance to SNCB of minimizing delays and passenger discomfort over the costs associated with servicing more trains to limit overcrowding. Our model’s cost-benefit analysis is designed with the concept that the most important variable for transportation planners (and our use case) is to limit overcrowding. Therefore, we assigned the true positive (Predicted train is overcrowded and train is overcrowded) variable with a number of “2” in relative importance, assuming that transportation planners add trains to the system to avoid overcrowding and delays. Meanwhile, we assigned the false positive variable (Predicted train was overcrowded and train is not overcrowded) with a value of -1, to indicate the cost of sending out additional trains that do not impact overcrowding. These numbers are our best guesses at the relative importance of these cases to SNCB planners, but only SNCB planners could indicate the actual importance. Therefore, working with SNCB to properly create an accurate cost-benefit analysis for their use is critical. Since ScheduRail is designed for SNCB planners, it will need their input to be successful. 
